# Project 2 Readme 

Purpose:

    In the United States buying a house is emblematic of the American Dream. Not only does it serve as a place of residence but real estate also serves as an important investment vehicle through which many Americans save for retirement. Given this importance, purchasing a home is probably going to be one of the largest financial decisions in an individual's life. Correct information regarding the true price of a house is paramount to make correct information regarding real estate. Many factors can influence the value of a property, most significantly the size of the house, total rooms, quality of the building but also location, year built and architectural style. The goal of this project is to create a model that takes various factors of a property and outputs a predicted housing price. 

About the Dataset:

    For this project we looked at properties sold in Ames, Iowa from 2006 to 2010. Ames is somewhat unique compared to other towns of similar size due to the presence of Iowa State University. The university is an important part of the local economy with around half the population of the town being students and another several thousand employees of the university. For this reason, Ames was relatively spared from the effects of the 2008 financial crash with the mean sale price only decreasing by about 8 percent or around  $10,000 from 2007 to 2010. With a population of around 60,000 in the late 2000’s Ames is a moderately sized town with numerous neighborhoods. The Stone Brook neighborhood had the highest average home prices at around $330000. Many of the highest cost areas were in newly built areas north and south of the city. The lowest were areas around the industrial sites east of the central business district. It’s no surprise that properties near industrial sites, railroads or arterial roads have a lower price compared to properties in quieter areas. When looking at factors of the property that affect its value, total living space and number of bedrooms and bathrooms deeply  affect the value of the property. Another important factor is a garage with garage size and number of car spaces highly correlated with sale price. Ultimately, there were nearly 80 columns in the data set. 

Making the Model and Results :

    For my model I tried to use as many of the available variables in the data set as possible. For quantitative variables, I performed basic EDA and added them to my list of features. For qualitative variables, I created dummy variables for each category and added those columns to the features. In total I had around 300 columns for my features data set.  For my test data set I then had to perform the same transformations and then add empty columns where the training and testing sets didn’t match. I decided to use a LASSO model because the large amount of features made it significantly overfit. A LASSO model would help to exclude variables affecting the quality of the model.  For the original train training model I got a R2 score of 0.93 for the training a 0.92 indicating the model was explaining more than 90 percent of the data. The model had an RMSE of 20851, indicating the model was off on average by more than $20,000. Although there are defitate ways this model could be improved compared to a simple linear regression model with just six features, the more complex LASSO model was significantly more accurate.  
